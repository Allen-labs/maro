env:
  scenario: "cim"
  topology: "toy.4p_ssdd_l0.0"
  durations: 1120
  state_shaping:
    look_back: 7
    max_ports_downstream: 2
  experience_shaping:
    time_window: 100
    fulfillment_factor: 1.0
    shortage_factor: 1.0
    time_decay_factor: 0.97
main_loop:
  max_episode: 500
  exploration:
    parameter_names:
      - "noise_stddev"
    start_values: 0.5
    end_values: 0.0
agents:
  min_action: -1.0
  max_action: 1.0
  policy_model:
    hidden_dims:
      - 128
      - 64
      - 32
    softmax_enabled: false
    batch_norm_enabled: true
    skip_connection_enabled: false
    dropout_p: 0.0
  policy_optimizer:
    lr: 0.01
  q_value_model:
    hidden_dims:
      - 128
      - 64
      - 32
    softmax_enabled: false
    batch_norm_enabled: true
    skip_connection_enabled: false
    dropout_p: 0.0
  q_value_optimizer:
    lr: 0.01
  hyper_params:
    reward_discount: .0
    target_update_frequency: 5
    policy_loss_coefficient: 1.0
    tau: 0.1
  training_loop_parameters:
    min_experiences_to_train: 1024
    num_batches: 10
    batch_size: 128
  seed: 32   # for reproducibility
